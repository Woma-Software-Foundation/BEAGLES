##########################
Darknet Layers Implemented
##########################

| ☑ activation - Not handled as a layer, more of a decoration for other layers.

   | ☐ logistic
   | ☐ loggy
   | ☑ relu
   | ☑ elu
   | ☐ selu
   | ☐ gelu
   | ☐ relie
   | ☐ ramp
   | ☐ linear
   | ☐ tanh
   | ☐ psle
   | ☑ leaky
   | ☑ stair
   | ☑ hardtan
   | ☐ lhtan

| ☑ avgpool
| ☑ batchnorm - Not handled as a layer, more of a decoration for other layers.
| ☑ connected
| ☑ conv-lstm
| ☑ convolutional
| ☑ cost - Not handled as layer, uses :obj:`beagles.backend.framework.NeuralNet`
| ☐ crnn
| ☑ crop
| ☐ deconvolutional
| ☑ detection - Not handled as a layer, Uses :obj:`beagles.backend.framework.Yolo`
| ☑ dropout
| ☐ Gaussian-yolo
| ☑ gru
| ☑ local
| ☑ lstm
| ☑ maxpool
| ☐ normalization
| ☑ region - Not handled as a layer, Uses :obj:`beagles.backend.framework.YoloV2`
| ☑ reorg
| ☑ rnn
| ☐ sam
| ☐ scale-channels
| ☑ shortcut
| ☑ softmax
| ☑ upsample
| ☐ yolo - May need to use a combination of Framework and Layer API








